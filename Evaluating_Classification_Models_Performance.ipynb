{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmN7yvpCsCaX"
   },
   "source": [
    "# Metrics To Evaluate Machine Learning Algorithms in Python\n",
    "\n",
    "The metrics that you choose to evaluate your machine learning algorithms are very important.\n",
    "\n",
    "Choice of metrics influences how the performance of machine learning algorithms is measured and compared. They influence how you weight the importance of different characteristics in the results and your ultimate choice of which algorithm to choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFcF03kDsCah"
   },
   "source": [
    "## Classification Metrics\n",
    "Classification problems are perhaps the most common type of machine learning problem and as such there are a myriad of metrics that can be used to evaluate predictions for these problems.\n",
    "\n",
    "In this section we will review how to use the following metrics:\n",
    "\n",
    "* Classification Accuracy.\n",
    "* Logarithmic Loss.\n",
    "* Area Under ROC Curve.\n",
    "* Confusion Matrix.\n",
    "* Classification Report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdSKyL2XsCah"
   },
   "source": [
    "## 1. Classification Accuracy\n",
    "Classification accuracy is the number of correct predictions made as a ratio of all predictions made.\n",
    "\n",
    "This is the most common evaluation metric for classification problems, it is also the most misused. It is really only suitable when there are an equal number of observations in each class (which is rarely the case) and that all predictions and prediction errors are equally important, which is often not the case.\n",
    "\n",
    "Below is an example of calculating classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1tVcSqOysCaj",
    "outputId": "0494ed3d-ade9-45b7-962e-c9b984c0fbee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.772 (0.050)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Accuracy\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)  # shuffle=True\n",
    "model = LogisticRegression(max_iter=500)\n",
    "scoring = 'accuracy'\n",
    "\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f\"Accuracy: {results.mean():.3f} ({results.std():.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF8Ega12sCan"
   },
   "source": [
    "You can see that the ratio is reported. This can be converted into a percentage by multiplying the value by 100, giving an accuracy score of approximately 77% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72sJhsc7sCap"
   },
   "source": [
    "### 2. Logarithmic Loss\n",
    "Logarithmic loss (or logloss) is a performance metric for evaluating the predictions of probabilities of membership to a given class.\n",
    "\n",
    "The scalar probability between 0 and 1 can be seen as a measure of confidence for a prediction by an algorithm. Predictions that are correct or incorrect are rewarded or punished proportionally to the confidence of the prediction.\n",
    "\n",
    "You can learn more about logarithmic on the Loss functions for classification Wikipedia article.\n",
    "\n",
    "Below is an example of calculating logloss for Logistic regression predictions on the Pima Indians onset of diabetes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Of-yGwddsCaq",
    "outputId": "f1e30541-a54a-4507-a45e-b1431aa68316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogLoss: -0.485 (0.057)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification LogLoss\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)  # shuffle=True\n",
    "model = LogisticRegression(max_iter=500)\n",
    "scoring = 'neg_log_loss'\n",
    "\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f\"LogLoss: {results.mean():.3f} ({results.std():.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdxTi1N-sCas"
   },
   "source": [
    "Smaller logloss is better with 0 representing a perfect logloss. As mentioned above, the measure is inverted to be ascending when using the cross_val_score() function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ymYrav-sCau"
   },
   "source": [
    "### 3. Area Under ROC Curve\n",
    "Area under ROC Curve (or AUC for short) is a performance metric for binary classification problems.\n",
    "\n",
    "The AUC represents a modelâ€™s ability to discriminate between positive and negative classes. An area of 1.0 represents a model that made all predictions perfectly. An area of 0.5 represents a model as good as random. Learn more about ROC here.\n",
    "\n",
    "ROC can be broken down into sensitivity and specificity. A binary classification problem is really a trade-off between sensitivity and specificity.\n",
    "\n",
    "Sensitivity is the true positive rate also called the recall. It is the number instances from the positive (first) class that actually predicted correctly.\n",
    "Specificity is also called the true negative rate. Is the number of instances from the negative class (second) class that were actually predicted correctly.\n",
    "\n",
    "The example below provides a demonstration of calculating AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "itJq0TfUsCav",
    "outputId": "2586f9df-013b-4b4f-e923-eb0fafa80870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.725 (0.063)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification ROC AUC\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)  # shuffle=True\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "scoring = 'roc_auc'\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f\"AUC: {results.mean():.3f} ({results.std():.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-dbPKmssCaw"
   },
   "source": [
    "You can see the the AUC is relatively close to 1 and greater than 0.5, suggesting some skill in the predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbBvP-x8sCax"
   },
   "source": [
    "### 4. Confusion Matrix\n",
    "The confusion matrix is a handy presentation of the accuracy of a model with two or more classes.\n",
    "\n",
    "The table presents predictions on the x-axis and accuracy outcomes on the y-axis. The cells of the table are the number of predictions made by a machine learning algorithm.\n",
    "\n",
    "For example, a machine learning algorithm can predict 0 or 1 and each prediction may actually have been a 0 or 1. Predictions for 0 that were actually 0 appear in the cell for prediction=0 and actual=0, whereas predictions for 0 that were actually 1 appear in the cell for prediction = 0 and actual=1. And so on.\n",
    "\n",
    "You can learn more about the Confusion Matrix on the Wikipedia article.\n",
    "\n",
    "Below is an example of calculating a confusion matrix for a set of prediction by a model on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIPdOYVTsCay",
    "outputId": "23a8f9d2-8043-4a98-9a0c-f4bf2a18d176"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[142  20]\n",
      " [ 34  58]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Confusion Matrix\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(Y_test, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEMZMPntsCa0"
   },
   "source": [
    "Although the array is printed without headings, you can see that the majority of the predictions fall on the diagonal line of the matrix (which are correct predictions).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgNIBWDysCa0"
   },
   "source": [
    "### 5. Classification Report\n",
    "Scikit-learn does provide a convenience report when working on classification problems to give you a quick idea of the accuracy of a model using a number of measures.\n",
    "\n",
    "The classification_report() function displays the precision, recall, f1-score and support for each class.\n",
    "\n",
    "The example below demonstrates the report on the binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LiVHC3YlsCa1",
    "outputId": "4f8992d1-8079-442e-edd8-0cfa54e3589b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.88      0.84       162\n",
      "         1.0       0.74      0.63      0.68        92\n",
      "\n",
      "    accuracy                           0.79       254\n",
      "   macro avg       0.78      0.75      0.76       254\n",
      "weighted avg       0.78      0.79      0.78       254\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Report\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YyjLhYDsCa-"
   },
   "source": [
    "### Summary\n",
    "\n",
    "##### 3 classification metrics:\n",
    "\n",
    "* Accuracy.\n",
    "* Logarithmic Loss.\n",
    "* Area Under ROC Curve.\n",
    "\n",
    "##### 2 convenience methods for classification prediction results:\n",
    "\n",
    "* Confusion Matrix.\n",
    "* Classification Report.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "4.7 Evaluating Classification Models Performance.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
